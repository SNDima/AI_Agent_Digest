# AI Agent Digest  

**AI Agent Digest** is an intelligent daily automated assistant that collects, scores, filters, and summarizes the most important news, research, and updates in the field of AI Agents. Using advanced LLM-based relevance scoring and smart filtering, it delivers high-quality content summaries to a dedicated Telegram channel every evening.  

## üöÄ Overview  
- **Smart Collection**: Gathers content from trusted RSS sources and real-time web search
- **AI-Powered Scoring**: Uses LLM to score article relevance (1-100) for AI agent content
- **Intelligent Filtering**: Automatically selects top articles based on relevance scores
- **AI Summarization**: Generates clear and concise summaries using OpenAI GPT models
- **Automated Delivery**: Publishes curated digest to Telegram on a reliable schedule  

## üìå Features (Current & Planned)  
- ‚úÖ **RSS Content Collection** from multiple sources (TechCrunch, Ars Technica, Gizmodo AI, LangChain Blog)
- ‚úÖ **Real-time Web Search** with SerpAPI via LangChain for latest AI agent news
- ‚úÖ **AI-Powered Summarization** using OpenAI GPT models for search results
- ‚úÖ **LLM-Based Relevance Scoring** (1-100 scale) for intelligent content filtering
- ‚úÖ **Smart Article Filtering** with configurable selection criteria (top 3-5 articles)
- ‚úÖ **Structured Output Processing** using Pydantic models for reliable data handling
- ‚úÖ **SQLite Database** with migration system for persistent storage
- ‚úÖ **Batch Operations** for improved performance and reliability
- ‚úÖ **Modular Configuration** with separate YAML files for each component
- ‚úÖ **Telegram Integration** for automated digest delivery
- ‚úÖ **Comprehensive Testing** with unit tests for all major components
- ‚¨ú **arXiv API Integration** for research paper collection
- ‚¨ú **Hugging Face Blog** support (RSS + scraping)
- ‚¨ú **Advanced Analytics** (engagement tracking, click metrics)
- ‚¨ú **Multi-language Support** for international content  

## üõ†Ô∏è Tech Stack  
- **Language**: Python 3.11+  
- **Workflow**: LangGraph for intelligent orchestration
- **AI Framework**: LangChain for tools and utilities
- **Content Sources**: RSS feeds, Web search APIs
- **Web Search**: SerpAPI via LangChain for real-time search results
- **AI Processing**: OpenAI GPT-4 models for summarization and scoring
- **Structured Output**: Pydantic models with `with_structured_output` for reliable data handling
- **Data Models**: Pydantic for type safety and validation
- **Storage**: SQLite with migration system (`db/migrations/`)  
- **Delivery**: Telegram Bot API  
- **Configuration**: YAML-based modular configuration system

## üìÇ Project Structure  
```
ai-agent-digest/
‚îÇ
‚îú‚îÄ‚îÄ config/            # Configuration files (YAML)
‚îÇ   ‚îú‚îÄ‚îÄ database.yaml  # Database configuration
‚îÇ   ‚îú‚îÄ‚îÄ sources.yaml   # RSS sources configuration
‚îÇ   ‚îú‚îÄ‚îÄ search_agent.yaml # Search agent configuration
‚îÇ   ‚îú‚îÄ‚îÄ scoring.yaml   # Relevance scoring configuration
‚îÇ   ‚îî‚îÄ‚îÄ delivery.yaml  # Delivery configuration
‚îú‚îÄ‚îÄ utils/             # Shared utility functions
‚îÇ   ‚îú‚îÄ‚îÄ config.py      # Configuration loading utilities
‚îÇ   ‚îú‚îÄ‚îÄ constants.py   # Configuration path constants
‚îÇ   ‚îî‚îÄ‚îÄ time_utils.py  # Time-based utility functions
‚îú‚îÄ‚îÄ sources/           # Content fetching and parsing
‚îÇ   ‚îî‚îÄ‚îÄ loader.py      # RSS feed loading and parsing
‚îú‚îÄ‚îÄ search/            # Web search and summarization
‚îÇ   ‚îî‚îÄ‚îÄ agent.py       # Search agent with SerpAPI integration
‚îú‚îÄ‚îÄ models/            # Data models (Pydantic)
‚îÇ   ‚îú‚îÄ‚îÄ article.py     # Article model with relevance scoring
‚îÇ   ‚îú‚îÄ‚îÄ search_result.py # Search result model
‚îÇ   ‚îú‚îÄ‚îÄ search_summary.py # Search summary model
‚îÇ   ‚îî‚îÄ‚îÄ delivery.py    # Delivery model
‚îú‚îÄ‚îÄ processing/        # Content processing pipeline
‚îÇ   ‚îú‚îÄ‚îÄ scoring.py     # LLM-based relevance scoring
‚îÇ   ‚îî‚îÄ‚îÄ filtering.py   # Smart article filtering
‚îú‚îÄ‚îÄ storage/           # Database operations
‚îÇ   ‚îú‚îÄ‚îÄ article_storage.py # Article database operations
‚îÇ   ‚îú‚îÄ‚îÄ summary_storage.py # Summary database operations
‚îÇ   ‚îî‚îÄ‚îÄ delivery_storage.py # Delivery database operations
‚îú‚îÄ‚îÄ delivery/          # Telegram integration
‚îÇ   ‚îî‚îÄ‚îÄ telegram.py    # Telegram bot integration
‚îú‚îÄ‚îÄ db/                # Database migrations
‚îÇ   ‚îú‚îÄ‚îÄ migrations/    # SQL migration scripts
‚îÇ   ‚îî‚îÄ‚îÄ migrate.py     # Migration runner
‚îú‚îÄ‚îÄ tests/             # Comprehensive test suite
‚îÇ   ‚îú‚îÄ‚îÄ test_time_utils.py
‚îÇ   ‚îú‚îÄ‚îÄ test_config.py
‚îÇ   ‚îî‚îÄ‚îÄ ...            # Additional test files
‚îú‚îÄ‚îÄ main.py            # Main workflow orchestration
‚îú‚îÄ‚îÄ requirements.txt   # Project dependencies
‚îú‚îÄ‚îÄ .env.example       # Environment variables template
‚îî‚îÄ‚îÄ README.md          # This file
```

## üîÑ Workflow Overview

The AI Agent Digest follows a sophisticated 7-step workflow:

1. **üì• Content Collection**: Fetches articles from RSS sources and stores them in SQLite
2. **üîç Web Search**: Performs real-time web searches for AI agent news using SerpAPI
3. **ü§ñ AI Summarization**: Generates comprehensive summaries using OpenAI GPT models
4. **üìä Relevance Scoring**: Uses LLM to score each article (1-100) for AI agent relevance
5. **üíæ Database Update**: Saves relevance scores to the database for persistence
6. **üéØ Smart Filtering**: Selects top 3-5 articles based on relevance scores
7. **üì± Telegram Delivery**: Publishes curated digest to Telegram channel

### üß† AI-Powered Scoring System

The relevance scoring system uses advanced LLM capabilities:

- **Intelligent Criteria**: Scores based on AI agent relevance, technical depth, and recency
- **Smart Filtering**: 
  - If ‚â•5 articles score >80: Selects top 5
  - If <5 articles score >80: Selects top 3
- **Reasoning Capture**: Captures LLM reasoning for each score


## ‚ö° Getting Started  
1. Clone the repository:  
   ```bash
   git clone https://github.com/yourusername/ai-agent-digest.git
   cd ai-agent-digest
   ```  
2. Create a virtual environment and install dependencies:  
   ```bash
   python -m venv venv
   source venv/bin/activate   # On Windows use venv\Scripts\activate
   pip install -r requirements.txt
   ```
   
   **Note**: The `requirements.txt` uses compatible version pinning (`~=`) for stability while allowing patch updates.  
3. Set up environment variables:
   ```bash
   # Rename the example file and add your API keys
   mv .env.example .env
   # Then edit .env with your actual API keys
   ```
4. Initialize or update the SQLite database (applies all migrations):  
   ```bash
   python -m db.migrate
   ```  
5. Run the agent:  
   ```bash
   python main.py
   ```

## üóÑ Database Migration Workflow  
- All schema changes are tracked as **SQL migration scripts** in `db/migrations/`.  
- Each migration file must follow the naming pattern: `NNN_description.sql` (e.g., `002_add_processed_flag.sql`).  
- Use the migration runner to apply all pending migrations:  
  ```bash
  python -m db.migrate
  ```
- The runner keeps track of applied migrations in a `schema_migrations` table.   

## üìñ Configuration  

### Environment Variables
Rename `.env.example` to `.env` and add your API keys:

```bash
# Rename the example file
mv .env.example .env

# Then edit .env with your actual values
```

### Database Configuration (`config/database.yaml`)
```yaml
database:
  file: "digest.db"
```

### Sources Configuration (`config/sources.yaml`)
```yaml
sources:
  - name: TechCrunch
    type: rss
    url: "https://techcrunch.com/category/artificial-intelligence/feed/"
    enabled: true
  - name: Ars Technica
    type: rss
    url: "https://arstechnica.com/ai/feed/"
    enabled: true
  # ... more sources
```

### Scoring Configuration (`config/scoring.yaml`)
```yaml
scoring:
  chat_model:
    model: "gpt-4.1"
    model_provider: "openai"
    temperature: 0.1
  scoring_prompt: |
    You are an expert content curator for an AI Agent Digest newsletter...
  system_message: "You are an expert AI content curator..."
```

### Search Agent Configuration (`config/search_agent.yaml`)
```yaml
search_agent:
  engine: google_news
  freshness: last_24h
  results_per_query: 5
  queries:
    - AI Agents
    - LangChain agents
    - autonomous AI agents
    - multi-agent systems
    - CrewAI OR AutoGen agents
```

### Configuration Features
- **Modular Configuration**: Separate YAML files for each component
- **Environment Variables**: Secure API key management via `.env`
- **Validation**: Pydantic models ensure configuration integrity
- **Flexible Database**: Configurable database location for different environments
- **Source Management**: Enable/disable sources individually
- **AI Customization**: Configurable LLM models and parameters

## üìú License  
This project is licensed under the **MIT License** ‚Äì see the [LICENSE](LICENSE) file for details.  

## ü§ù Contributing  
Contributions are welcome! Please open an issue or submit a pull request if you‚Äôd like to help improve the project.  

## üåü Future Enhancements  
- **Advanced Analytics**: Engagement tracking, click metrics, read time analysis
- **Cloud Deployment**: Docker containers, serverless functions